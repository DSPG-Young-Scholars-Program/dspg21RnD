{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/sbc8kw/git/dspg21RnD/data/dspg21RnD/nmf_bert_10.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-808dabdb0a21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnmf_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/sbc8kw/git/dspg21RnD/data/dspg21RnD/nmf_bert_10.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnmf_c\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_topics'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnmf_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnmf_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/sbc8kw/git/dspg21RnD/data/dspg21RnD/nmf_bert_10.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/HT_Bert/lib/python3.8/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \"\"\"\n\u001b[1;32m    184\u001b[0m     \u001b[0mexcs_to_catch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/HT_Bert/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/sbc8kw/git/dspg21RnD/data/dspg21RnD/nmf_bert_10.pkl'"
     ]
    }
   ],
   "source": [
    "nmf_c = pd.read_pickle(\"/home/sbc8kw/git/dspg21RnD/data/dspg21RnD/nmf_bert_10.pkl\")\n",
    "nmf_c['n_topics'] = nmf_c.index\n",
    "nmf_c.to_csv(\"/home/sbc8kw/git/dspg21RnD/data/dspg21RnD/nmf_bert_10.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/sfs/qumulo/qhome/scb8kw/git/dspg21RnD/src/04_eads_method'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scb8kw/.conda/envs/HT_Bert/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import time\n",
    "\n",
    "from sklearn.decomposition import NMF, TruncatedSVD, LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_c = pd.read_pickle(\"../../data/dspg21RnD/nmf_Eads_10.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_c['n_topics'] = nmf_c.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_c.to_csv(\"../../data/dspg21RnD/nmf_eads_10.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics(model, vectorizer, top_n=10):\n",
    "    for idx, topic in enumerate(model.components_):  # loop through each row of H.  idx = row index.  topic = actual row\n",
    "        print(\"\\nTopic %d:\" % (idx))\n",
    "        #print([(vectorizer.get_feature_names()[i], topic[i])  # printing out words corresponding to indices found in next line\n",
    "                        #for i in topic.argsort()[:-top_n - 1:-1]])  # finding indices of top words in topic\n",
    "            \n",
    "        print_list = [(vectorizer.get_feature_names()[i], topic[i])  \n",
    "                        for i in topic.argsort()[:-top_n - 1:-1]]\n",
    "        for item in print_list:\n",
    "            print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:Input a dataframe that are ai related abstracts, need variables: final_frqwds_removed\n",
    "abstracts = pd.read_csv(r'/home/zz3hs/git/dspg21RnD/data/dspg21RnD/Eads_AI_abstracts-KL.csv') \n",
    "abstracts2 = pd.read_csv(r'/home/zz3hs/git/dspg21RnD/data/dspg21RnD/Eads_AI_abstracts.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6930"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lim_docs = abstracts[\"final_frqwds_removed\"]\n",
    "len(lim_docs)\n",
    "\n",
    "lim_docs2 = abstracts2[\"final_frqwds_removed\"]\n",
    "len(lim_docs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input needed for LDA, NMF (all from Scikit-Learn) is one string per document (not a list of strings)\n",
    "\n",
    "text1 = []\n",
    "\n",
    "for token_list in lim_docs:\n",
    "    text1.append(token_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "text2 = []\n",
    "\n",
    "for token_list in lim_docs2:\n",
    "    text2.append(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6930, 10635)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a TF-IDF document-term matrix for the AI corpus \n",
    "\n",
    "# TRY DIFFERENT PARAMETERS IN THE TF-IDF DOC-TERM MATRIX SET-UP\n",
    "nmf_vectorizer1 = TfidfVectorizer(max_df=1.0, min_df=3, lowercase=True) #, max_features=int(len(lim_docs)/2))\n",
    "nmf_vectorizer2 = TfidfVectorizer(max_df=1.0, min_df=3, lowercase=True) #, max_features=int(len(lim_docs)/2))\n",
    "\n",
    "# by default TfidfVectorizer has l2 normalization for rows: \n",
    "# from Scikit Learn documentation: Each output row will have unit norm, either: * ‘l2’: Sum of squares of vector \n",
    "# elements is 1. The cosine similarity between two vectors is their dot product when l2 norm has been applied.\n",
    "\n",
    "nmf_tf_idf1 = nmf_vectorizer1.fit_transform(text1)\n",
    "nmf_tf_idf1.shape\n",
    "\n",
    "\n",
    "nmf_tf_idf2 = nmf_vectorizer2.fit_transform(text2)\n",
    "nmf_tf_idf2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean+2 SD (k=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scb8kw/.conda/envs/HT_Bert/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n",
      "/home/scb8kw/.conda/envs/HT_Bert/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1090: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    }
   ],
   "source": [
    "# topic modeling with NMF\n",
    "nmf_model1 = NMF(n_components=30, random_state=1)  # TRY DIFFERENT NUMBERS OF TOPICS\n",
    "W1 = nmf_model1.fit_transform(nmf_tf_idf1)\n",
    "H1 = nmf_model1.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 0:\n",
      "('statistical', 4.28411347240657)\n",
      "('dimensional', 3.013426178136023)\n",
      "('inference', 1.754060779077917)\n",
      "('variable', 1.7071651103777452)\n",
      "('estimation', 1.5863325865603506)\n",
      "('selection', 1.2219754844887192)\n",
      "('statistic', 1.1711564147239808)\n",
      "('methodology', 1.0077736708796323)\n",
      "('parameter', 0.9820065119251911)\n",
      "('theory', 0.9695090309350993)\n",
      "('dimension', 0.8873370303985251)\n",
      "('set', 0.8748827986761154)\n",
      "('estimate', 0.8267270080771003)\n",
      "('procedure', 0.7701391397275305)\n",
      "('distribution', 0.7526533290015504)\n",
      "\n",
      "Topic 1:\n",
      "('auditory', 2.617536460719778)\n",
      "('sound', 2.2724648901860296)\n",
      "('hearing', 0.8178113211856096)\n",
      "('processing', 0.6002034660740172)\n",
      "('auditory_cortex', 0.5032867542302544)\n",
      "('temporal', 0.5028194790535857)\n",
      "('acoustic', 0.4961230021743314)\n",
      "('perception', 0.3386036477079593)\n",
      "('listener', 0.3169449779932742)\n",
      "('vocal', 0.28821576614236477)\n",
      "('cortical', 0.2718732014263432)\n",
      "('neural', 0.26962700748675)\n",
      "('source', 0.2671521064320304)\n",
      "('loss', 0.246511883472998)\n",
      "('communication', 0.24046660733060538)\n",
      "\n",
      "Topic 2:\n",
      "('language', 2.755315744445477)\n",
      "('linguistic', 0.5195797260669524)\n",
      "('bilingual', 0.35351545126092515)\n",
      "('sign', 0.26744936469466607)\n",
      "('natural', 0.2601554455272173)\n",
      "('processing', 0.24545129120210926)\n",
      "('speaker', 0.22961451951432085)\n",
      "('text', 0.22054669086406006)\n",
      "('english', 0.17134761768103376)\n",
      "('sentence', 0.17081129995605143)\n",
      "('nlp', 0.1417089271667979)\n",
      "('native', 0.13935903320510376)\n",
      "('second', 0.13080959336900094)\n",
      "('translation', 0.13036627767812375)\n",
      "('learner', 0.12423379942138575)\n",
      "\n",
      "Topic 3:\n",
      "('robot', 2.9957572490242415)\n",
      "('robotics', 0.5084117749335724)\n",
      "('task', 0.4655303425251704)\n",
      "('robotic', 0.4498082814709885)\n",
      "('environment', 0.41689145582625975)\n",
      "('manipulation', 0.30920269779407045)\n",
      "('planning', 0.29948631211876287)\n",
      "('manufacturing', 0.24942292259933282)\n",
      "('autonomous', 0.24882341572705854)\n",
      "('team', 0.2391132253210615)\n",
      "('object', 0.23161067546953235)\n",
      "('interaction', 0.19506264869080378)\n",
      "('enable', 0.1795002939921992)\n",
      "('physical', 0.1686634682040161)\n",
      "('people', 0.1600154911923647)\n",
      "\n",
      "Topic 4:\n",
      "('patient', 2.47002465214205)\n",
      "('clinical', 1.5939479609608131)\n",
      "('care', 1.2545182468579539)\n",
      "('health', 1.1477098824377143)\n",
      "('medical', 0.5997361583908138)\n",
      "('nlp', 0.49001674974640524)\n",
      "('healthcare', 0.48480744387464453)\n",
      "('ehr', 0.4019174809677071)\n",
      "('electronic', 0.3938100680170551)\n",
      "('decision', 0.35574591003917716)\n",
      "('record', 0.33577014578968545)\n",
      "('clinician', 0.33463913864673744)\n",
      "('hospital', 0.3259629063281768)\n",
      "('report', 0.2998747862742138)\n",
      "('pain', 0.29956472280813434)\n",
      "\n",
      "Topic 5:\n",
      "('speech', 2.9243736531002917)\n",
      "('recognition', 0.46010825154760987)\n",
      "('speaker', 0.4390000113275635)\n",
      "('production', 0.40359207596303526)\n",
      "('acoustic', 0.33373828168414305)\n",
      "('voice', 0.23974248440621548)\n",
      "('speak', 0.2176018616421494)\n",
      "('speech_perception', 0.2071561372814416)\n",
      "('listener', 0.19517081733194305)\n",
      "('motor', 0.1883331783400149)\n",
      "('noise', 0.15319892892232506)\n",
      "('talker', 0.13958240471489236)\n",
      "('articulatory', 0.13612526956331195)\n",
      "('feedback', 0.12769330073890722)\n",
      "('phonetic', 0.12489490469550753)\n",
      "\n",
      "Topic 6:\n",
      "('student', 1.9824051387445207)\n",
      "('conference', 0.8509352798371842)\n",
      "('science', 0.7767551686258425)\n",
      "('workshop', 0.7702347092094445)\n",
      "('graduate', 0.4324437810979141)\n",
      "('undergraduate', 0.40440512412825813)\n",
      "('opportunity', 0.36097021164045234)\n",
      "('engineering', 0.3598672606991679)\n",
      "('computer', 0.3583783603477487)\n",
      "('faculty', 0.34145458413711366)\n",
      "('school', 0.3376171501018957)\n",
      "('career', 0.33000217175587154)\n",
      "('education', 0.3287050244670729)\n",
      "('participant', 0.31630857290778513)\n",
      "('international', 0.290517848690159)\n",
      "\n",
      "Topic 7:\n",
      "('image', 3.0906473068428073)\n",
      "('imaging', 0.5112191073229287)\n",
      "('feature', 0.4241080913990265)\n",
      "('text', 0.3345650783595713)\n",
      "('segmentation', 0.3028418708221595)\n",
      "('search', 0.2710956823592293)\n",
      "('vision', 0.23524423347703527)\n",
      "('retrieval', 0.22897910019658085)\n",
      "('deep', 0.22859899658532193)\n",
      "('medical', 0.22439463493993192)\n",
      "('cell', 0.22372319939496987)\n",
      "('3d', 0.21075243047774236)\n",
      "('representation', 0.20862888959278475)\n",
      "('recognition', 0.20519984487614973)\n",
      "('database', 0.19604070472379811)\n",
      "\n",
      "Topic 8:\n",
      "('protein', 3.8730076343221667)\n",
      "('sequence', 0.7236045842544065)\n",
      "('prediction', 0.6521539011592449)\n",
      "('interaction', 0.5992172613096954)\n",
      "('drug', 0.45983807537425897)\n",
      "('biological', 0.4423483777876211)\n",
      "('molecular', 0.4293818976305622)\n",
      "('molecule', 0.3640147001937588)\n",
      "('computational', 0.35114718876821605)\n",
      "('structural', 0.29545405889620135)\n",
      "('predict', 0.2909431708087572)\n",
      "('experimental', 0.25419745999612114)\n",
      "('bind', 0.2320820425151487)\n",
      "('modeling', 0.22513234904710736)\n",
      "('residue', 0.2123221026195119)\n",
      "\n",
      "Topic 9:\n",
      "('network', 3.9901254179714383)\n",
      "('node', 0.3801708238152572)\n",
      "('dynamic', 0.28071955070142407)\n",
      "('biological', 0.27917084470084025)\n",
      "('wireless', 0.24030774517122397)\n",
      "('connectivity', 0.2043051696881552)\n",
      "('deep', 0.19755483604858093)\n",
      "('distribute', 0.191323105560779)\n",
      "('communication', 0.1805048839650932)\n",
      "('traffic', 0.1781322503324645)\n",
      "('sensor', 0.16990546251765096)\n",
      "('framework', 0.16924939049524115)\n",
      "('embedding', 0.1534911284805461)\n",
      "('neural', 0.15062041815866328)\n",
      "('dynamics', 0.1498986742383539)\n",
      "\n",
      "Topic 10:\n",
      "('learning', 2.626558579072538)\n",
      "('learn', 1.5437062416826552)\n",
      "('deep', 0.46837850018221805)\n",
      "('learner', 0.36081673507605405)\n",
      "('reinforcement', 0.2931988054676235)\n",
      "('task', 0.251373477548475)\n",
      "('environment', 0.23715286610662362)\n",
      "('stem', 0.23498039706260881)\n",
      "('student', 0.1943775363978095)\n",
      "('transfer', 0.17163917615240876)\n",
      "('category', 0.16938353366589307)\n",
      "('reward', 0.16718713716748987)\n",
      "('game', 0.15910696643872185)\n",
      "('feedback', 0.1587877338169374)\n",
      "('domain', 0.15339295415224088)\n",
      "\n",
      "Topic 11:\n",
      "('brain', 3.3071069770986337)\n",
      "('imaging', 0.44271951106979607)\n",
      "('functional', 0.415088566573198)\n",
      "('fmri', 0.4027563232296694)\n",
      "('region', 0.3865768401723487)\n",
      "('connectivity', 0.35858968086089366)\n",
      "('mri', 0.2742469428291143)\n",
      "('pattern', 0.2515185979719849)\n",
      "('disorder', 0.24442888980538474)\n",
      "('neuroimaging', 0.22540966715945307)\n",
      "('neuroscience', 0.22300379936339304)\n",
      "('subject', 0.17214337918851771)\n",
      "('spatial', 0.1571131244062147)\n",
      "('resolution', 0.15405090603009738)\n",
      "('eeg', 0.15218511169828952)\n",
      "\n",
      "Topic 12:\n",
      "('visual', 3.2059780346817774)\n",
      "('object', 1.3552245509952414)\n",
      "('vision', 0.856414875543813)\n",
      "('scene', 0.7935464856372463)\n",
      "('recognition', 0.4984130637721341)\n",
      "('perception', 0.4849622568916062)\n",
      "('representation', 0.38527487777248176)\n",
      "('perceptual', 0.35826795283870627)\n",
      "('world', 0.2779057865134903)\n",
      "('cortex', 0.25399786989785456)\n",
      "('stimuli', 0.2517844098521094)\n",
      "('natural', 0.249971721535604)\n",
      "('video', 0.23944047102058597)\n",
      "('shape', 0.22276941420189064)\n",
      "('action', 0.21178877024804188)\n",
      "\n",
      "Topic 13:\n",
      "('cancer', 4.548672279555708)\n",
      "('tumor', 1.3391519523468434)\n",
      "('breast', 1.0496573555566888)\n",
      "('lung', 0.6591729286918458)\n",
      "('biomarker', 0.6305342509723122)\n",
      "('cell', 0.5897798598884025)\n",
      "('therapy', 0.5863209220742387)\n",
      "('clinical', 0.5087505185657858)\n",
      "('prostate', 0.46473963784817957)\n",
      "('imaging', 0.4596920003778402)\n",
      "('screen', 0.44658923515238025)\n",
      "('molecular', 0.4428054797409952)\n",
      "('patient', 0.41804809576037544)\n",
      "('melanoma', 0.36249566292543217)\n",
      "('drug', 0.3597893394338587)\n",
      "\n",
      "Topic 14:\n",
      "('human', 2.99268435982218)\n",
      "('interaction', 0.39320258266749153)\n",
      "('machine', 0.3428513433147291)\n",
      "('computer', 0.25457983488107094)\n",
      "('action', 0.2265931482886871)\n",
      "('interface', 0.19847585881193658)\n",
      "('people', 0.17832709414836379)\n",
      "('task', 0.16368170882670652)\n",
      "('decision', 0.1591790446076032)\n",
      "('cognitive', 0.15687336146147635)\n",
      "('operator', 0.15325608631551935)\n",
      "('movement', 0.1475717472658239)\n",
      "('safety', 0.14017721915308393)\n",
      "('robotic', 0.13692288984031992)\n",
      "('intelligent', 0.12984602071000248)\n",
      "\n",
      "Topic 15:\n",
      "('graph', 3.587817164490346)\n",
      "('edge', 0.27781678500495066)\n",
      "('algorithm', 0.2374556629512275)\n",
      "('node', 0.21282726083503464)\n",
      "('mining', 0.1928932323182452)\n",
      "('analytics', 0.18630555852557865)\n",
      "('spectral', 0.18239611572374956)\n",
      "('processing', 0.15386322915960562)\n",
      "('theory', 0.14201455801694543)\n",
      "('domain', 0.13940625807048057)\n",
      "('efficient', 0.13893053678457284)\n",
      "('represent', 0.13085269806697297)\n",
      "('set', 0.13038113486928776)\n",
      "('abstraction', 0.12867219971969102)\n",
      "('representation', 0.12261150235062704)\n",
      "\n",
      "Topic 16:\n",
      "('algorithm', 2.467882366526054)\n",
      "('optimization', 1.1450432872151057)\n",
      "('theory', 0.5016746677261192)\n",
      "('efficient', 0.48158882812698395)\n",
      "('computational', 0.44977760946849366)\n",
      "('machine_learning', 0.43906350903955677)\n",
      "('uncertainty', 0.42513006143953985)\n",
      "('scale', 0.38135902363196145)\n",
      "('stochastic', 0.38077150811751176)\n",
      "('theoretical', 0.37325995922574107)\n",
      "('algorithmic', 0.3711520341103271)\n",
      "('computer', 0.36876927912372187)\n",
      "('decision', 0.3350096421704609)\n",
      "('pi', 0.318775891804375)\n",
      "('solution', 0.31117407542772046)\n",
      "\n",
      "Topic 17:\n",
      "('neural', 2.586537873052519)\n",
      "('cognitive', 1.5609121501738648)\n",
      "('task', 1.1287439555234817)\n",
      "('memory', 0.8373413348570169)\n",
      "('behavioral', 0.6808720516966164)\n",
      "('representation', 0.5622685491845747)\n",
      "('circuit', 0.40773641273285605)\n",
      "('processing', 0.3429079636081668)\n",
      "('neuroscience', 0.3374956985756684)\n",
      "('schizophrenia', 0.27151299523226646)\n",
      "('disorder', 0.2650439309179086)\n",
      "('deficit', 0.24044053395694062)\n",
      "('cognition', 0.23692404968116743)\n",
      "('underlying', 0.22004061950118783)\n",
      "('hippocampus', 0.21649575582970312)\n",
      "\n",
      "Topic 18:\n",
      "('word', 4.0416171058406585)\n",
      "('infant', 0.8029151318855106)\n",
      "('comprehension', 0.437139295056049)\n",
      "('representation', 0.41398673114160167)\n",
      "('meaning', 0.3774155290028677)\n",
      "('reading', 0.3648014956274522)\n",
      "('lexical', 0.34651071985385345)\n",
      "('document', 0.3259309118792045)\n",
      "('speak', 0.3010051611356917)\n",
      "('semantic', 0.2895322833932456)\n",
      "('recognition', 0.2573754473940007)\n",
      "('learn', 0.2543991891435206)\n",
      "('phonological', 0.25258935748990136)\n",
      "('memory', 0.22920050554343127)\n",
      "('vocabulary', 0.20512880626808885)\n",
      "\n",
      "Topic 19:\n",
      "('software', 0.9589063064739284)\n",
      "('computing', 0.6801630967373916)\n",
      "('user', 0.6591429368097521)\n",
      "('technology', 0.6217411397828169)\n",
      "('energy', 0.5335050404634)\n",
      "('device', 0.518720748320236)\n",
      "('platform', 0.4899232631171676)\n",
      "('enable', 0.4800224977080606)\n",
      "('hardware', 0.4503444832583964)\n",
      "('performance', 0.4492683159672058)\n",
      "('infrastructure', 0.4204308584187798)\n",
      "('sensor', 0.3923779462612102)\n",
      "('architecture', 0.3710595633353113)\n",
      "('analytics', 0.36413916270033886)\n",
      "('power', 0.36391573433655283)\n",
      "\n",
      "Topic 20:\n",
      "('biomedical', 1.177115898123643)\n",
      "('phenotype', 0.9825160989974999)\n",
      "('predictive', 0.7208429827833616)\n",
      "('modeling', 0.7099418385925322)\n",
      "('health', 0.5734377041235038)\n",
      "('source', 0.5673119892384524)\n",
      "('phenotyping', 0.5538982727974427)\n",
      "('object', 0.5482110459660475)\n",
      "('biology', 0.5364128600847078)\n",
      "('computational', 0.47919346420994585)\n",
      "('clinically', 0.4508866572887747)\n",
      "('challenge', 0.4336353085276782)\n",
      "('prediction', 0.4045343992760623)\n",
      "('advance', 0.3505816965706889)\n",
      "('scale', 0.3451890290551105)\n",
      "\n",
      "Topic 21:\n",
      "('social', 2.2620252435809096)\n",
      "('interaction', 0.5480372741767497)\n",
      "('media', 0.518471454571189)\n",
      "('people', 0.44334775049445607)\n",
      "('online', 0.42023320822580784)\n",
      "('user', 0.3918911583736133)\n",
      "('team', 0.34612758354010265)\n",
      "('individual', 0.32587299868695635)\n",
      "('science', 0.28725345294442756)\n",
      "('agent', 0.2735914753280533)\n",
      "('behavioral', 0.254124547361099)\n",
      "('health', 0.2505609522030336)\n",
      "('content', 0.23855994463135344)\n",
      "('public', 0.2060590554842413)\n",
      "('policy', 0.1890068546696109)\n",
      "\n",
      "Topic 22:\n",
      "('range', 2.8380691258351054)\n",
      "('wide', 0.18957237301113386)\n",
      "('broad', 0.0980253525558142)\n",
      "('severity', 0.0685633336167513)\n",
      "('species', 0.06064728476774849)\n",
      "('dynamic', 0.058870428836284364)\n",
      "('partner', 0.05236158487824352)\n",
      "('burden', 0.05219567718460264)\n",
      "('aspect', 0.039971114552049755)\n",
      "('estimation', 0.03789436069617125)\n",
      "('frequency', 0.03788756666828818)\n",
      "('adaptation', 0.036662522476926716)\n",
      "('distribution', 0.03385330656043088)\n",
      "('temporal', 0.033637356725009795)\n",
      "('space', 0.029817571417908764)\n",
      "\n",
      "Topic 23:\n",
      "('gene', 2.1902592826044147)\n",
      "('cell', 1.0615657334510087)\n",
      "('genetic', 0.871049671838601)\n",
      "('genome', 0.82639743553702)\n",
      "('variant', 0.5526225033159222)\n",
      "('genomic', 0.5152909962457136)\n",
      "('regulatory', 0.4405150454425219)\n",
      "('dna', 0.4202403535171911)\n",
      "('biological', 0.38603233818340316)\n",
      "('sequence', 0.3852939713494823)\n",
      "('drug', 0.36472543422375736)\n",
      "('association', 0.32631082455999005)\n",
      "('snp', 0.32188114813147534)\n",
      "('rna', 0.29889996885536335)\n",
      "('phenotype', 0.2723390933455905)\n",
      "\n",
      "Topic 24:\n",
      "('attention', 2.1918703436511473)\n",
      "('attentional', 0.46929986710260513)\n",
      "('visual', 0.238777106308925)\n",
      "('selective', 0.23428641480247195)\n",
      "('spatial', 0.1716474777957245)\n",
      "('selection', 0.17043734087461643)\n",
      "('task', 0.16786591675142296)\n",
      "('sensory', 0.15289852927086697)\n",
      "('neuronal', 0.14480452516989697)\n",
      "('stimulus', 0.13902265025414964)\n",
      "('infant', 0.13645422147366087)\n",
      "('behavioral', 0.1213065267541315)\n",
      "('deficit', 0.11903508441811164)\n",
      "('cortical', 0.11823727177932664)\n",
      "('attend', 0.11753683555549502)\n",
      "\n",
      "Topic 25:\n",
      "('ad', 2.1452893772192367)\n",
      "('alzheimer', 0.45941689453050777)\n",
      "('biomarker', 0.4059939450285546)\n",
      "('dementia', 0.3766224430713523)\n",
      "('cognitive', 0.3592114872955824)\n",
      "('pathology', 0.21615636568597962)\n",
      "('mri', 0.2038235146280993)\n",
      "('imaging', 0.1933148808568157)\n",
      "('mci', 0.17915082833111606)\n",
      "('aging', 0.17888670100786808)\n",
      "('clinical', 0.1743331981502459)\n",
      "('decline', 0.17148916792410504)\n",
      "('diagnosis', 0.17007693932226003)\n",
      "('age', 0.16969584297785226)\n",
      "('longitudinal', 0.1485088247995413)\n",
      "\n",
      "Topic 26:\n",
      "('child', 2.520400303567151)\n",
      "('asd', 0.6083991492449892)\n",
      "('developmental', 0.27456319730007495)\n",
      "('age', 0.25857730833567005)\n",
      "('adult', 0.24732580040578211)\n",
      "('language', 0.22228376647567208)\n",
      "('infant', 0.21706319876675362)\n",
      "('skill', 0.21462678885514064)\n",
      "('autism', 0.20670710872431158)\n",
      "('disorder', 0.1788904122797937)\n",
      "('impairment', 0.16565326283315898)\n",
      "('young', 0.16526273785924145)\n",
      "('parent', 0.16156413611508436)\n",
      "('deficit', 0.1551832529413663)\n",
      "('vocabulary', 0.15240847851703654)\n",
      "\n",
      "Topic 27:\n",
      "('animal', 2.3671576832579864)\n",
      "('agent', 0.6356560428975073)\n",
      "('small', 0.38010136898220964)\n",
      "('behavioral', 0.2784130469527877)\n",
      "('species', 0.2737225166207367)\n",
      "('non_human_primate', 0.19608474127151115)\n",
      "('environment', 0.1500836728490737)\n",
      "('transgenic', 0.14273002165862514)\n",
      "('iaa', 0.13172881701993872)\n",
      "('ethanol', 0.1306078057144394)\n",
      "('therapeutics', 0.12842123013947987)\n",
      "('pathogen', 0.12782721851086484)\n",
      "('vivo', 0.11765185090553626)\n",
      "('efficacy', 0.1175442579020548)\n",
      "('standardization', 0.11186393654558638)\n",
      "\n",
      "Topic 28:\n",
      "('motion', 1.9497250284881558)\n",
      "('movement', 0.25885983834679427)\n",
      "('planning', 0.2567567986502929)\n",
      "('perception', 0.17511815312783888)\n",
      "('hand', 0.16527198739070195)\n",
      "('environment', 0.1440174380116137)\n",
      "('self', 0.1393271443930529)\n",
      "('synthesis', 0.13609867606679157)\n",
      "('simulation', 0.1331262210052195)\n",
      "('dynamic', 0.11710456527949781)\n",
      "('eye', 0.11504744989272493)\n",
      "('capture', 0.11253296391896103)\n",
      "('body', 0.10151976974446696)\n",
      "('mt', 0.1014491967150391)\n",
      "('task', 0.10014967131634309)\n",
      "\n",
      "Topic 29:\n",
      "('neuron', 2.0580146841895894)\n",
      "('sensory', 0.952906668725856)\n",
      "('circuit', 0.5287805615155281)\n",
      "('cell', 0.40954672398415376)\n",
      "('input', 0.3633125239451261)\n",
      "('cortical', 0.3572783174894984)\n",
      "('neural', 0.3436557054210991)\n",
      "('motor', 0.30424461630379046)\n",
      "('neuronal', 0.3000273981645704)\n",
      "('single', 0.25570773411927905)\n",
      "('stimuli', 0.23641473638301522)\n",
      "('stimulus', 0.21393272414652698)\n",
      "('property', 0.2048495618929231)\n",
      "('olfactory', 0.19534592139445023)\n",
      "('pattern', 0.1893299515980976)\n"
     ]
    }
   ],
   "source": [
    "print_topics(nmf_model1, nmf_vectorizer1, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean+2.5 SD(k=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scb8kw/.conda/envs/HT_Bert/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n",
      "/home/scb8kw/.conda/envs/HT_Bert/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1090: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    }
   ],
   "source": [
    "#topic modeling with NMF\n",
    "\n",
    "nmf_model2 = NMF(n_components=30, random_state=1)  # TRY DIFFERENT NUMBERS OF TOPICS\n",
    "W2 = nmf_model2.fit_transform(nmf_tf_idf2)\n",
    "H2 = nmf_model2.components_\n",
    "#print_topics(nmf_model, nmf_vectorizer, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 0:\n",
      "('algorithm', 3.917278675376787)\n",
      "('optimization', 1.4722133105537567)\n",
      "('theory', 1.3694693005378042)\n",
      "('theoretical', 0.9033537774861806)\n",
      "('algorithmic', 0.9025461526631919)\n",
      "('approximation', 0.8267589552481186)\n",
      "('computational', 0.8251253878517142)\n",
      "('complexity', 0.8032012886128949)\n",
      "('pi', 0.7937748349450169)\n",
      "('statistical', 0.7824651641201522)\n",
      "('efficient', 0.7555003174901294)\n",
      "('machine_learning', 0.7383280382150686)\n",
      "('fundamental', 0.6724292720460755)\n",
      "('linear', 0.6549985144072823)\n",
      "('dimensional', 0.6321668366741362)\n",
      "\n",
      "Topic 1:\n",
      "('robot', 3.321292436884194)\n",
      "('robotics', 0.639824360562042)\n",
      "('robotic', 0.5196932667791098)\n",
      "('task', 0.49532173098099114)\n",
      "('planning', 0.4574184752612381)\n",
      "('manipulation', 0.43247903499687984)\n",
      "('environment', 0.39407081251746334)\n",
      "('motion', 0.37777673587139826)\n",
      "('object', 0.31575134117152553)\n",
      "('autonomous', 0.2516468980013222)\n",
      "('manufacturing', 0.236117660456319)\n",
      "('enable', 0.19982846697494605)\n",
      "('action', 0.19190967313721297)\n",
      "('people', 0.18742644601133476)\n",
      "('team', 0.1802569712118403)\n",
      "\n",
      "Topic 2:\n",
      "('network', 3.4996005269539516)\n",
      "('node', 0.30438378429229973)\n",
      "('traffic', 0.2602794215212265)\n",
      "('wireless', 0.2026462817508402)\n",
      "('link', 0.17468288270030535)\n",
      "('internet', 0.1653103012487147)\n",
      "('networking', 0.15327341574068784)\n",
      "('protocol', 0.1527391602787161)\n",
      "('dynamic', 0.14089231737994162)\n",
      "('topology', 0.12960059487424963)\n",
      "('dynamics', 0.12829814391085426)\n",
      "('cellular', 0.12115565812266484)\n",
      "('embedding', 0.11949743189686653)\n",
      "('biological', 0.11692763020410599)\n",
      "('inference', 0.11677252359901545)\n",
      "\n",
      "Topic 3:\n",
      "('conference', 1.7384517239325274)\n",
      "('student', 1.0149516219792958)\n",
      "('international', 0.7156571958115782)\n",
      "('doctoral', 0.617192767848517)\n",
      "('consortium', 0.4701562893843984)\n",
      "('attend', 0.45167830409866927)\n",
      "('travel', 0.4425025753584739)\n",
      "('participant', 0.41602364297078315)\n",
      "('opportunity', 0.35480141784500685)\n",
      "('us', 0.3485599609223098)\n",
      "('senior', 0.31679300037508473)\n",
      "('participation', 0.3082218836275657)\n",
      "('hold', 0.2684320510757372)\n",
      "('career', 0.2648818043163222)\n",
      "('feedback', 0.24474899397920746)\n",
      "\n",
      "Topic 4:\n",
      "('image', 2.3603604781692984)\n",
      "('object', 1.3229397457181977)\n",
      "('visual', 0.9356790852370915)\n",
      "('vision', 0.933098844100058)\n",
      "('scene', 0.7658559017201827)\n",
      "('recognition', 0.6541295893868453)\n",
      "('video', 0.6032676342222888)\n",
      "('shape', 0.48256665826677364)\n",
      "('representation', 0.4475024142285673)\n",
      "('3d', 0.44447424841588007)\n",
      "('computer', 0.39496496567824635)\n",
      "('category', 0.29640967206649665)\n",
      "('imaging', 0.27042998259607787)\n",
      "('semantic', 0.2491743026744745)\n",
      "('appearance', 0.24660254595235329)\n",
      "\n",
      "Topic 5:\n",
      "('language', 3.7388902919115505)\n",
      "('natural', 0.8495102417364293)\n",
      "('programming', 0.747821707517865)\n",
      "('text', 0.582084324201254)\n",
      "('translation', 0.5718517640087137)\n",
      "('linguistic', 0.5667163822017867)\n",
      "('semantic', 0.5213178198345104)\n",
      "('word', 0.4072104420478098)\n",
      "('processing', 0.34930534540165625)\n",
      "('nlp', 0.31355395891219323)\n",
      "('sentence', 0.3002826401295932)\n",
      "('english', 0.2880429403871852)\n",
      "('representation', 0.25152620890941685)\n",
      "('programmer', 0.24152954892319373)\n",
      "('level', 0.24063707991146696)\n",
      "\n",
      "Topic 6:\n",
      "('graph', 3.6153640277843255)\n",
      "('edge', 0.2457115655051912)\n",
      "('spectral', 0.243158505653716)\n",
      "('node', 0.23377751749877454)\n",
      "('algorithm', 0.21202649321817124)\n",
      "('mining', 0.14967252029971553)\n",
      "('represent', 0.13881617206632918)\n",
      "('subgraph', 0.13159969038339764)\n",
      "('processing', 0.1275594038013616)\n",
      "('social', 0.1193779449577656)\n",
      "('representation', 0.1179859260523471)\n",
      "('property', 0.1163207064793143)\n",
      "('relationship', 0.11508847334574691)\n",
      "('sampling', 0.109456353333985)\n",
      "('analytics', 0.10836090651502117)\n",
      "\n",
      "Topic 7:\n",
      "('big', 2.60777202891763)\n",
      "('analytics', 1.128476841170238)\n",
      "('infrastructure', 0.4087034505314289)\n",
      "('science', 0.39280757169095204)\n",
      "('scale', 0.3891259665448593)\n",
      "('scientific', 0.3763204008375935)\n",
      "('dataset', 0.3722787157334536)\n",
      "('discovery', 0.35699023960359827)\n",
      "('challenge', 0.304917598858548)\n",
      "('mining', 0.28696813645159314)\n",
      "('storage', 0.27613650566108944)\n",
      "('enable', 0.2738333792697749)\n",
      "('scalable', 0.23968587422366228)\n",
      "('management', 0.22068838736976681)\n",
      "('cloud', 0.21930662895150907)\n",
      "\n",
      "Topic 8:\n",
      "('workshop', 2.6825716224592764)\n",
      "('participant', 0.4043511869085994)\n",
      "('bring', 0.3242706593813345)\n",
      "('science', 0.3058144801469481)\n",
      "('computational', 0.28620471316178075)\n",
      "('acl', 0.28242058441573337)\n",
      "('discussion', 0.2754434243354367)\n",
      "('discuss', 0.2727030687708739)\n",
      "('organize', 0.2533244677798787)\n",
      "('linguistic', 0.24612656420485313)\n",
      "('vision', 0.19980216911711637)\n",
      "('expert', 0.19907331528019945)\n",
      "('papers', 0.19591846695044904)\n",
      "('opportunity', 0.18749646521352345)\n",
      "('report', 0.18571959053575868)\n",
      "\n",
      "Topic 9:\n",
      "('learning', 2.0418309393070126)\n",
      "('learn', 1.6251059607472123)\n",
      "('deep', 0.5282294253023737)\n",
      "('learner', 0.49044518882851823)\n",
      "('technology', 0.3889734689480835)\n",
      "('machine_learning', 0.34542680712918344)\n",
      "('cyberlearning', 0.22575823886585708)\n",
      "('teacher', 0.2245453163192524)\n",
      "('machine', 0.22332461524661076)\n",
      "('representation', 0.21349642325284893)\n",
      "('environment', 0.20337303578532206)\n",
      "('classroom', 0.2008070416896617)\n",
      "('task', 0.19148795458759613)\n",
      "('reinforcement', 0.1900400745224549)\n",
      "('online', 0.17617728288999454)\n",
      "\n",
      "Topic 10:\n",
      "('user', 2.8261117516322436)\n",
      "('interface', 0.8564416593216401)\n",
      "('device', 0.5165139143983563)\n",
      "('interaction', 0.513629307593827)\n",
      "('mobile', 0.44047097380594225)\n",
      "('virtual', 0.32022536237864474)\n",
      "('people', 0.30662697386192417)\n",
      "('gesture', 0.2504473960805318)\n",
      "('pi', 0.23445875405937955)\n",
      "('touch', 0.2299704728824505)\n",
      "('access', 0.21753482689054376)\n",
      "('interactive', 0.20517974137019124)\n",
      "('environment', 0.20486112264908926)\n",
      "('technology', 0.1924836855868717)\n",
      "('security', 0.1862121697401755)\n",
      "\n",
      "Topic 11:\n",
      "('brain', 2.2319211621170205)\n",
      "('neural', 1.1982437913299424)\n",
      "('neuron', 0.6064853273323378)\n",
      "('neuroscience', 0.4719097571241013)\n",
      "('cognitive', 0.2584433966370621)\n",
      "('functional', 0.2522046544418316)\n",
      "('cortical', 0.25191810301281403)\n",
      "('imaging', 0.24626334899972735)\n",
      "('spike', 0.24304402613775897)\n",
      "('stimuli', 0.22366628441480746)\n",
      "('computational', 0.2178461368337845)\n",
      "('circuit', 0.21510985743137584)\n",
      "('cell', 0.2095142342314075)\n",
      "('sensory', 0.19963978305563462)\n",
      "('pattern', 0.18970721979431923)\n",
      "\n",
      "Topic 12:\n",
      "('software', 2.2607482189440367)\n",
      "('code', 0.7732111984506467)\n",
      "('developer', 0.4428638806250214)\n",
      "('testing', 0.3708277840950775)\n",
      "('source', 0.36694710193687535)\n",
      "('engineering', 0.3458025370790617)\n",
      "('test', 0.2901883985905813)\n",
      "('open', 0.2606911684121258)\n",
      "('verification', 0.2526923931064491)\n",
      "('bug', 0.23345739558551523)\n",
      "('specification', 0.2117944090482363)\n",
      "('programming', 0.21024686354383942)\n",
      "('automated', 0.20977611642595795)\n",
      "('programmer', 0.20756684771697914)\n",
      "('infrastructure', 0.1919620102332751)\n",
      "\n",
      "Topic 13:\n",
      "('sensor', 2.1371670450202833)\n",
      "('sense', 1.2415864238387107)\n",
      "('environment', 0.5584999082658495)\n",
      "('mobile', 0.403959408449932)\n",
      "('monitoring', 0.3400238418207677)\n",
      "('vehicle', 0.2532701181860002)\n",
      "('real', 0.23629124102519883)\n",
      "('smart', 0.23105254073201073)\n",
      "('environmental', 0.2269295306469734)\n",
      "('device', 0.2231530947504851)\n",
      "('physical', 0.22212943087082182)\n",
      "('wearable', 0.21504071056043325)\n",
      "('building', 0.19962162131051076)\n",
      "('stream', 0.19150805680643898)\n",
      "('camera', 0.19136902019145566)\n",
      "\n",
      "Topic 14:\n",
      "('search', 1.5770020348776679)\n",
      "('document', 0.9460839982687373)\n",
      "('text', 0.8470692081400909)\n",
      "('web', 0.7224889879197661)\n",
      "('retrieval', 0.47605418663551013)\n",
      "('search_engine', 0.4281448089420311)\n",
      "('event', 0.41332886016818604)\n",
      "('dataset', 0.39967557571299556)\n",
      "('content', 0.37321842197486016)\n",
      "('collection', 0.32745949589762957)\n",
      "('source', 0.3033065479425308)\n",
      "('rank', 0.2973153939917294)\n",
      "('pattern', 0.2874237834988808)\n",
      "('domain', 0.23275135551453963)\n",
      "('extraction', 0.23271875439886755)\n",
      "\n",
      "Topic 15:\n",
      "('visualization', 2.4796860339526234)\n",
      "('visual', 0.849306505729567)\n",
      "('interactive', 0.33977884693563914)\n",
      "('uncertainty', 0.32760889220809564)\n",
      "('scientific', 0.299824399105895)\n",
      "('simulation', 0.24590303155502213)\n",
      "('exploration', 0.23075843217909536)\n",
      "('scientist', 0.22841407095408794)\n",
      "('analyst', 0.2219335197403747)\n",
      "('domain', 0.21863509075868062)\n",
      "('dataset', 0.19712004663039448)\n",
      "('display', 0.19312520216178108)\n",
      "('visualize', 0.18786273298809297)\n",
      "('analytics', 0.17065082459801129)\n",
      "('representation', 0.16177821269755902)\n",
      "\n",
      "Topic 16:\n",
      "('agent', 2.598151495818318)\n",
      "('game', 0.6948623568654284)\n",
      "('action', 0.42653443427826593)\n",
      "('decision', 0.4011313930827872)\n",
      "('market', 0.2828119014222575)\n",
      "('theory', 0.26260693433519006)\n",
      "('environment', 0.22867524083147117)\n",
      "('multi_agent', 0.22035685614754888)\n",
      "('strategic', 0.21730352962838761)\n",
      "('player', 0.19653289416643435)\n",
      "('planning', 0.17238883046548)\n",
      "('task', 0.17121074961658478)\n",
      "('autonomous', 0.16624662706785076)\n",
      "('reward', 0.15982656479355378)\n",
      "('ai', 0.1593254475553435)\n",
      "\n",
      "Topic 17:\n",
      "('social', 2.7175247921396357)\n",
      "('media', 0.8978586882952826)\n",
      "('online', 0.5743975170307137)\n",
      "('people', 0.5062378200875711)\n",
      "('interaction', 0.4422158830341544)\n",
      "('individual', 0.34464594860372666)\n",
      "('child', 0.24377512596155668)\n",
      "('content', 0.2293354332074712)\n",
      "('science', 0.2098653242654016)\n",
      "('team', 0.20070458016517856)\n",
      "('public', 0.18516424349709174)\n",
      "('relationship', 0.1782405143633624)\n",
      "('influence', 0.17335253879679424)\n",
      "('analyze', 0.16322233461630256)\n",
      "('technology', 0.15985519934764633)\n",
      "\n",
      "Topic 18:\n",
      "('speech', 1.8819863518643507)\n",
      "('recognition', 0.4830854822837336)\n",
      "('speaker', 0.398154749367071)\n",
      "('acoustic', 0.29801319455004593)\n",
      "('child', 0.2727766114545104)\n",
      "('voice', 0.2233720255539994)\n",
      "('sound', 0.18677248993965784)\n",
      "('automatic', 0.18085853593482018)\n",
      "('emotion', 0.17743935168829394)\n",
      "('speak', 0.15745479388589784)\n",
      "('audio', 0.14832468011995648)\n",
      "('emotional', 0.14427996391191447)\n",
      "('feature', 0.13251261779694057)\n",
      "('production', 0.12957543664638654)\n",
      "('noise', 0.1274657470549537)\n",
      "\n",
      "Topic 19:\n",
      "('human', 2.218576980649102)\n",
      "('interaction', 0.38480497351190135)\n",
      "('task', 0.28617296098656536)\n",
      "('machine', 0.2600743950117238)\n",
      "('computer', 0.2254890731477771)\n",
      "('cognitive', 0.21835824526634287)\n",
      "('motion', 0.18897736979581037)\n",
      "('operator', 0.18213537825847867)\n",
      "('visual', 0.1543766306990789)\n",
      "('vision', 0.13349979079885976)\n",
      "('perception', 0.12965758265811156)\n",
      "('interface', 0.1292514538543053)\n",
      "('people', 0.12607131436057822)\n",
      "('decision', 0.12449849254053992)\n",
      "('safety', 0.123226840269108)\n",
      "\n",
      "Topic 20:\n",
      "('distribute', 1.8346685049995295)\n",
      "('communication', 1.2564827421846394)\n",
      "('channel', 0.5429631597950223)\n",
      "('coding', 0.39407769296926487)\n",
      "('wireless', 0.2874173685995893)\n",
      "('team', 0.2817209987256568)\n",
      "('coordination', 0.2569785952315339)\n",
      "('computation', 0.24360128918167276)\n",
      "('scale', 0.22737441907284678)\n",
      "('message', 0.20493148377581444)\n",
      "('node', 0.19386480681585833)\n",
      "('code', 0.18824652573016765)\n",
      "('computing', 0.18045372289560133)\n",
      "('theory', 0.17511191218117197)\n",
      "('delay', 0.16300898929557006)\n",
      "\n",
      "Topic 21:\n",
      "('cps', 1.2308155007703503)\n",
      "('security', 1.2003781730766452)\n",
      "('attack', 0.9552424727353379)\n",
      "('cyber_physical', 0.6342003319557183)\n",
      "('safety', 0.3986388483516986)\n",
      "('detection', 0.35933180207672605)\n",
      "('real', 0.31282823749556615)\n",
      "('secure', 0.3051533540744527)\n",
      "('vulnerability', 0.28637919263310524)\n",
      "('malware', 0.27776655206570366)\n",
      "('verification', 0.249284085427567)\n",
      "('physical', 0.2456909819826578)\n",
      "('defense', 0.22782884904391856)\n",
      "('vehicle', 0.22203329544500813)\n",
      "('traffic', 0.2163990308633281)\n",
      "\n",
      "Topic 22:\n",
      "('privacy', 2.0137238747641315)\n",
      "('private', 0.43656286442120756)\n",
      "('policy', 0.3849760858203039)\n",
      "('differential', 0.2539605839800428)\n",
      "('privacy_preserve', 0.21124901848474717)\n",
      "('concern', 0.2067897755018877)\n",
      "('protect', 0.18745037302418888)\n",
      "('individual', 0.16860793079630343)\n",
      "('utility', 0.155737889376934)\n",
      "('mining', 0.1550104994946122)\n",
      "('sensitive', 0.15297929380165834)\n",
      "('people', 0.14653194757294047)\n",
      "('statistical', 0.1424523414586541)\n",
      "('share', 0.14088399678135982)\n",
      "('dataset', 0.13622466879539624)\n",
      "\n",
      "Topic 23:\n",
      "('energy', 1.5054812276424538)\n",
      "('power', 0.9236654404282767)\n",
      "('device', 0.7913497496811344)\n",
      "('circuit', 0.5086361833804468)\n",
      "('hardware', 0.4189522393423471)\n",
      "('computing', 0.4157629235468873)\n",
      "('efficiency', 0.34257916319301435)\n",
      "('low', 0.33634240041951435)\n",
      "('consumption', 0.32966386988138086)\n",
      "('iot', 0.2838114748772488)\n",
      "('architecture', 0.2834269524507062)\n",
      "('mobile', 0.28325406930171404)\n",
      "('efficient', 0.26944212369618586)\n",
      "('performance', 0.24190487747775713)\n",
      "('embed', 0.21582662503443775)\n",
      "\n",
      "Topic 24:\n",
      "('student', 1.23312981234718)\n",
      "('science', 0.6988711925503052)\n",
      "('reu', 0.51185206565816)\n",
      "('undergraduate', 0.4400870788062358)\n",
      "('site', 0.425899824004114)\n",
      "('computer', 0.4064710558672073)\n",
      "('school', 0.3829301357523418)\n",
      "('engineering', 0.30609356809696364)\n",
      "('faculty', 0.29547391240033927)\n",
      "('education', 0.28306937503540475)\n",
      "('graduate', 0.2751540128080896)\n",
      "('summer', 0.26301782666253315)\n",
      "('university', 0.23442867040658413)\n",
      "('teacher', 0.2327465527162079)\n",
      "('career', 0.23151626095593208)\n",
      "\n",
      "Topic 25:\n",
      "('protein', 1.2841789043717908)\n",
      "('gene', 0.6594967523278905)\n",
      "('molecular', 0.5708606902457142)\n",
      "('biological', 0.5643975182591671)\n",
      "('simulation', 0.4615629162027681)\n",
      "('computational', 0.4596022417432668)\n",
      "('biology', 0.40396375304132165)\n",
      "('genome', 0.3979470865644494)\n",
      "('cell', 0.38855384835684575)\n",
      "('interaction', 0.3718496587725963)\n",
      "('sequence', 0.3243661913438695)\n",
      "('modeling', 0.303253991244337)\n",
      "('molecule', 0.21946194145202372)\n",
      "('scale', 0.2151663998020614)\n",
      "('space', 0.2015561251436261)\n",
      "\n",
      "Topic 26:\n",
      "('memory', 1.0781699332477317)\n",
      "('parallel', 0.7102096476957138)\n",
      "('performance', 0.7075170742733605)\n",
      "('computing', 0.6329243817040705)\n",
      "('architecture', 0.49741062347433884)\n",
      "('programming', 0.4110307835738861)\n",
      "('hardware', 0.40112398755994916)\n",
      "('processor', 0.37139424207320737)\n",
      "('computation', 0.3497923006298496)\n",
      "('processing', 0.29497748847698796)\n",
      "('parallelism', 0.24671282333908498)\n",
      "('compiler', 0.24408493176687426)\n",
      "('storage', 0.22695681991607417)\n",
      "('level', 0.2168580935744445)\n",
      "('scale', 0.209501146088139)\n",
      "\n",
      "Topic 27:\n",
      "('spectrum', 1.576127751152759)\n",
      "('wireless', 0.8194385383272506)\n",
      "('radio', 0.8029268521661902)\n",
      "('cognitive', 0.6616972289246205)\n",
      "('channel', 0.22684450374342718)\n",
      "('rf', 0.20773901247762547)\n",
      "('access', 0.19813212305601705)\n",
      "('share', 0.18757512513888222)\n",
      "('protocol', 0.18411328647646147)\n",
      "('frequency', 0.16180506694858682)\n",
      "('communication', 0.1574215424267662)\n",
      "('networking', 0.15608566250050762)\n",
      "('sense', 0.15450360589595968)\n",
      "('crn', 0.1504533790746811)\n",
      "('utilization', 0.1440608260968028)\n",
      "\n",
      "Topic 28:\n",
      "('query', 2.0040268900618328)\n",
      "('database', 0.7047035025610445)\n",
      "('uncertainty', 0.27936101053005985)\n",
      "('probabilistic', 0.2742520485335428)\n",
      "('processing', 0.2629819666394941)\n",
      "('management', 0.2408953365076034)\n",
      "('uncertain', 0.2310966217425113)\n",
      "('web', 0.19882547485944693)\n",
      "('answer', 0.18585644698967696)\n",
      "('efficient', 0.11956709743290896)\n",
      "('set', 0.11081152368422394)\n",
      "('index', 0.09614857911578534)\n",
      "('integration', 0.0919248868969264)\n",
      "('efficiently', 0.09024472194838751)\n",
      "('approximate', 0.0900869674258913)\n",
      "\n",
      "Topic 29:\n",
      "('patient', 1.0742416855116013)\n",
      "('health', 0.8882590541633473)\n",
      "('clinical', 0.5123587952273071)\n",
      "('medical', 0.4403187228250343)\n",
      "('care', 0.40666762870477197)\n",
      "('healthcare', 0.3062676205793431)\n",
      "('prediction', 0.2075617780867849)\n",
      "('machine_learning', 0.18476461817622447)\n",
      "('record', 0.18203368150175123)\n",
      "('home', 0.17404691997301874)\n",
      "('population', 0.16235125095932823)\n",
      "('individual', 0.16178156501314894)\n",
      "('decision', 0.15286334257948855)\n",
      "('electronic', 0.15245043922594326)\n",
      "('personalize', 0.1458389707501753)\n"
     ]
    }
   ],
   "source": [
    "print_topics(nmf_model2, nmf_vectorizer2, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-HT_Bert]",
   "language": "python",
   "name": "conda-env-.conda-HT_Bert-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
