{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the LDA topic model on the NSF - cfda = 47.070 on the final tokens column instead of frq words removed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7/28/21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import numpy as np\n",
    "import filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_dictionary(lda_model, lda_vectorizer, top_n = 10):\n",
    "    topic_ls = {} #append keys, append the values\n",
    "    \n",
    "    for idx, topic in enumerate(lda_model.components_):  # loop through each row of H.  idx = row index.  topic = actual row\n",
    "\n",
    "        print_list = [(lda_vectorizer.get_feature_names()[i], topic[i])  \n",
    "                        for i in topic.argsort()[:-top_n - 1:-1]]\n",
    "        topic_ls[idx] = print_list\n",
    "\n",
    "    return topic_ls\n",
    "\n",
    "def print_topics(model, vectorizer, top_n=10):\n",
    "    for idx, topic in enumerate(model.components_):  # loop through each row of H.  idx = row index.  topic = actual row\n",
    "        print(\"\\nTopic %d:\" % (idx))\n",
    "            \n",
    "        print_list = [(vectorizer.get_feature_names()[i], topic[i])  \n",
    "                        for i in topic.argsort()[:-top_n - 1:-1]]\n",
    "        for item in print_list:\n",
    "            print(item)\n",
    "            \n",
    "            \n",
    "def relevant_topics(topic_dictionary, keyword_list, threshold = 0.15):\n",
    "    \"\"\"returns a list of the topics which contain a threshold % of the\n",
    "    relevant words in the keyword list\"\"\"\n",
    "    relevant_topic = []\n",
    "    for key in topic_dictionary:\n",
    "        relevant_words = 0\n",
    "        for i in range(len(topic_dictionary[key])):\n",
    "            if topic_dictionary[key][i][0] in keyword_list:\n",
    "                relevant_words += 1\n",
    "        if (relevant_words) / len(topic_dictionary[key]) >= threshold :\n",
    "            relevant_topic.append(key)\n",
    "    return relevant_topic  \n",
    "\n",
    "def rel_ent_key_list(topic_model, vectorizer, n_top_keywords, relevant_topics):\n",
    "    \"\"\"Returns a list of the top n keywords based on relative entropy score\n",
    "     Arguments:\n",
    "       topic_model (TopicModel): a topic by vocabulary word matrix where each entry\n",
    "       is the total word count for that word in that topic\n",
    "       n_top_words (int): the number of keywords the method will return\n",
    "       relevant_topics (iterable of int)\n",
    "     Returns:\n",
    "       keyword_list (iterable of str): list of the top n keywords, sorted\n",
    "     \"\"\"\n",
    "    topic_word_matrix = topic_model.components_\n",
    "    lda_vectorizer = vectorizer\n",
    "    \n",
    "    vocab_logs = np.log(topic_word_matrix.sum(\n",
    "        axis=0) / topic_word_matrix.sum())\n",
    "\n",
    "    topic_logs = np.log(topic_word_matrix[relevant_topics, :].sum(\n",
    "        axis=0) / topic_word_matrix[relevant_topics, :].sum())\n",
    "\n",
    "    unsorted_props = np.asarray(topic_word_matrix.sum(axis=0) /\n",
    "                                topic_word_matrix.sum()) * np.asarray(topic_logs - vocab_logs)\n",
    "\n",
    "    unsorted_props = np.matrix.flatten(unsorted_props)\n",
    "\n",
    "    sorted_props_and_voc = sorted([(unsorted_props[i], lda_vectorizer.get_feature_names()[i]) for i in list(\n",
    "        np.argpartition(unsorted_props, len(lda_vectorizer.get_feature_names()) - n_top_keywords))[-n_top_keywords:]], reverse=True)\n",
    "    ordered_vocab = []\n",
    "    for (_, voc) in sorted_props_and_voc:\n",
    "        ordered_vocab.append(voc)\n",
    "    return ordered_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start with the core terms from the OECD paper\n",
    "core_terms = [\"adaboost\",\"artificial intelligence\",\"artificial neural network\",\"back propagation\"\n",
    ",\"back propagation neural network\",\"computational intelligence\",\"computer vision\"\n",
    ",\"convolutional neural network\",\"deep belief network\",\"deep convolutional neural network\"\n",
    ",\"deep learn\",\"deep neural network\",\"elman network\",\"elman neural network\"\n",
    ",\"expert system\",\"fee forward neural network\",\"inference engine\",\"machine intelligence\"\n",
    ",\"machine learn\",\"machine translation\",\"machine vision\",\"multilayer neural network\"\n",
    ",\"natural language process\",\"perceptron\",\"random forest\",\"rbf neural network\",\"recurrent neural network\"\n",
    ",\"self organize map\",\"spike neural network\",\"supervise learn\",\"support vector machine\"\n",
    ",\"svm classifier\",\"unsupervised learn\",\"artificial_intelligence\",\"artificial_neural_network\",\"back_propagation\"\n",
    ",\"back_propagation_neural_network\",\"computational_intelligence\",\"computer_vision\"\n",
    ",\"convolutional_neural_network\",\"deep_belief_network\",\"deep_convolutional_neural_network\"\n",
    ",\"deep_learn\",\"deep_neural_network\",\"elman_network\",\"elman_neural_network\"\n",
    ",\"expert_system\",\"fee_forward_neural_network\",\"inference_engine\",\"machine_intelligence\"\n",
    ",\"machine_learn\",\"machine_translation\",\"machine_vision\",\"multilayer_neural_network\"\n",
    ",\"natural_language_process\",\"random_forest\",\"rbf_neural_network\",\"recurrent_neural_network\"\n",
    ",\"self_organize_map\",\"spike_neural_network\",\"supervise_learn\",\"support_vector_machine\"\n",
    ",\"svm_classifier\",\"unsupervised_learn\", \"machine_learning\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../data/dspg21RnD/smaller-final-dataset.pkl\")\n",
    "nsf = df[df[\"AGENCY\"] == \"NSF\"]\n",
    "# filter where cfda = 47.070\n",
    "\n",
    "nsf_csci = nsf[nsf[\"CFDA_CODE\"] == \"47.070\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16416 entries, 1996 to 689833\n",
      "Data columns (total 31 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   original index              16416 non-null  int64  \n",
      " 1   PROJECT_ID                  16416 non-null  object \n",
      " 2   ABSTRACT                    16416 non-null  object \n",
      " 3   FY                          16416 non-null  object \n",
      " 4   ORG_COUNT                   16416 non-null  int64  \n",
      " 5   PI_COUNT                    16416 non-null  int64  \n",
      " 6   nchar                       16416 non-null  int64  \n",
      " 7   final_frqwds_removed        16416 non-null  object \n",
      " 8   PROJECT_TERMS               16416 non-null  object \n",
      " 9   PROJECT_TITLE               16416 non-null  object \n",
      " 10  DEPARTMENT                  16416 non-null  object \n",
      " 11  AGENCY                      16416 non-null  object \n",
      " 12  IC_CENTER                   0 non-null      object \n",
      " 13  PROJECT_NUMBER              16416 non-null  object \n",
      " 14  PROJECT_START_DATE          16416 non-null  object \n",
      " 15  PROJECT_END_DATE            16416 non-null  object \n",
      " 16  CONTACT_PI_PROJECT_LEADER   16416 non-null  object \n",
      " 17  OTHER_PIS                   5332 non-null   object \n",
      " 18  CONGRESSIONAL_DISTRICT      16411 non-null  object \n",
      " 19  DUNS_NUMBER                 16414 non-null  object \n",
      " 20  ORGANIZATION_NAME           16416 non-null  object \n",
      " 21  ORGANIZATION_CITY           16416 non-null  object \n",
      " 22  ORGANIZATION_STATE          16411 non-null  object \n",
      " 23  ORGANIZATION_ZIP            16411 non-null  object \n",
      " 24  ORGANIZATION_COUNTRY        16416 non-null  object \n",
      " 25  BUDGET_START_DATE           0 non-null      object \n",
      " 26  BUDGET_END_DATE             0 non-null      object \n",
      " 27  CFDA_CODE                   16416 non-null  object \n",
      " 28  FY.y                        16416 non-null  object \n",
      " 29  FY_TOTAL_COST               16347 non-null  float64\n",
      " 30  FY_TOTAL_COST_SUB_PROJECTS  0 non-null      float64\n",
      "dtypes: float64(2), int64(4), object(25)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "nsf_csci.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nsf_csci[\"final_frqwds_removed\"]\n",
    "\n",
    "text = [] # text will contain the processed tokens in string form (1 string per abstract)\n",
    "\n",
    "\n",
    "for abstract in tokens:\n",
    "    text.append(\" \".join(abstract))\n",
    "    \n",
    "text = pd.Series(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRY TOPIC MODELING WITH LDA\n",
    "\n",
    "lda_vectorizer = CountVectorizer(max_df=0.6, min_df=20)\n",
    "\n",
    "\n",
    "lda_dtm = lda_vectorizer.fit_transform(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-HT_Bert]",
   "language": "python",
   "name": "conda-env-.conda-HT_Bert-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
