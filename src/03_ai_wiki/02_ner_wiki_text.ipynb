{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition on AI Wiki text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Crystal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Major package used: Stanza "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4552042aa76348889f8dc7584510c919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.1.json:   0%|   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-27 19:13:20 INFO: Downloading default packages for language: en (English)...\n",
      "2021-06-27 19:13:21 INFO: File exists: /home/zz3hs/stanza_resources/en/default.zip.\n",
      "2021-06-27 19:13:26 INFO: Finished downloading models and saved to /home/zz3hs/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "\n",
    "\n",
    "# web scrapping\n",
    "import requests as r\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import bs4 as bs\n",
    "import urllib\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "#name entity recognition\n",
    "import stanza\n",
    "stanza.download('en') # download English model\n",
    "\n",
    "#spacy\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#visualization\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "import warnings\n",
    "#warnings.simplefilter('always')\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in AI Wiki text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#texts = open(\"/home/zz3hs/git/dspg21RnD/data/dspg21RnD/ai_wiki_text.txt\", \"r\")\n",
    "with open(\"/home/zz3hs/git/dspg21RnD/data/dspg21RnD/ai_wiki_text.txt\") as f:\n",
    "    contents = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First paragraph: oneNoneArtificial intelligence (AI) is intelligence demonstrated by machines, unlike the natural intelligence displayed by humans and animals, which involves consciousness and emotionality. The distinction between the former and the latter categories is often revealed by the acronym chosen. 'Strong' AI is usually labelled as artificial general intelligence (AGI) while attempts to emulate 'natural' intelligence have been called artificial biological intelligence (ABI). Leading AI textbooks define the field as the study of \"intelligent agents\": any device that perceives its environment and takes actions that maximize its chance of achieving its goals.  Colloquially, the term \"artificial intelligence\" is often used to describe machines that mimic \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem solving\". \n",
      "As machines become increasingly capable, tasks considered to require \"intelligence\" are often removed from the definition of AI, a phenom\n",
      "Last paragraph: e familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity. \n",
      "Transhumanism (the merging of humans and machines) is explored in the manga Ghost in the Shell and the science-fiction series Dune. In the 1980s, artist Hajime Sorayama's Sexy Robots series were painted and published in Japan depicting the actual organic human form with lifelike muscular metallic skins and later \"the Gynoids\" book followed that was used by or influenced movie makers including George Lucas and other creatives. Sorayama never considered these organic robots to be real part of nature but alwa\n"
     ]
    }
   ],
   "source": [
    "len(contents)\n",
    "print(\"First paragraph:\",contents[1:1000])\n",
    "\n",
    "print(\"Last paragraph:\", contents[61100:61759])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-27 19:13:29 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2021-06-27 19:13:29 INFO: Use device: cpu\n",
      "2021-06-27 19:13:29 INFO: Loading: tokenize\n",
      "2021-06-27 19:13:29 INFO: Loading: ner\n",
      "2021-06-27 19:13:30 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,ner') # initialize English neural pipeline, tokenize and named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Document will contain a list of Sentences, and the Sentences will contain lists of Tokens. \n",
    "doc = nlp(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract named entities\n",
    "entities = doc.entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "395"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"text\": \"Tesler\",\n",
       "  \"type\": \"PERSON\",\n",
       "  \"start_char\": 1040,\n",
       "  \"end_char\": 1046\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for entity in entities:\n",
    "    df = df.append({\n",
    "        \"text\": entity.text,\n",
    "        'type': entity.type,\n",
    "        'start_char': entity.start_char,\n",
    "        'end_char': entity.end_char\n",
    "        }, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save name entity recognition on AI Wiki text as a panda dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(r'/home/zz3hs/git/dspg21RnD/data/dspg21RnD/ai_wiki_text_entity.csv', index = True) #export csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-crystal]",
   "language": "python",
   "name": "conda-env-.conda-crystal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
