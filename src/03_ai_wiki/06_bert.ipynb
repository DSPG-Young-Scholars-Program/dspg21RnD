{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Sentence Bert Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Crystal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bert\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "#nltk.download() #input: punkt\n",
    "\n",
    "from nltk import tokenize\n",
    "\n",
    "#embeddings\n",
    "embedder = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "#embedder = SentenceTransformer(\"allenai/scibert_scivocab_uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2667c9d32d254611add54653d20263fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_corpus_embeddings(dir):\n",
    "    with open(dir) as f:\n",
    "        ai_text = f.read()\n",
    "    ai_corpus = tokenize.sent_tokenize(ai_text) #sentence tokenization\n",
    "    ai_embeddings = embedder.encode(ai_corpus, show_progress_bar=True) # embeddings\n",
    "    return ai_embeddings\n",
    "\n",
    "\n",
    "ai_embeddings = get_corpus_embeddings(\"/home/zz3hs/git/dspg21RnD/data/dspg21RnD/ai_wiki_text.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k: number of similar sentences from AI corpus\n",
    "# abstract: abstract from FEDERAL RePORTER\n",
    "# print_result: if TRUE, print out the similar sentenses from AI corpus to each sentence in the abstract\n",
    "def get_score(k, abstract, print_result = False):\n",
    "    queries = tokenize.sent_tokenize(abstract) \n",
    "\n",
    "    # init a result list for scores\n",
    "    result = []\n",
    "    \n",
    "    # Find the closest k sentences of the AI corpus for each query sentence (ML) based on cosine similarity\n",
    "    top_k = min(k, len(ai_corpus))\n",
    "    \n",
    "    for query in queries: #compare each sentence in the abstract to the ai corpus\n",
    "        query_embedding = embedder.encode(query, show_progress_bar=False) \n",
    "        \n",
    "        # We use cosine-similarity and torch.topk to find the highest k scores\n",
    "        cos_scores = util.pytorch_cos_sim(query_embedding, ai_embeddings)[0]\n",
    "        \n",
    "        top_results = torch.topk(cos_scores, k=top_k)   #get the top k scores\n",
    "        result.append(top_results.values.tolist()) #unlist the top result list\n",
    "        if print_result:\n",
    "            print(\"\\n\\n======================\\n\\n\")\n",
    "            print(\"Query:\", query)\n",
    "            print(\"Results:\", top_results)\n",
    "            print(\"\\nTop k=5 most similar sentences in corpus:\")\n",
    "            for score, idx in zip(top_results[0], top_results[1]):\n",
    "                print(ai_corpus[idx], \"(Score: {:.4f})\".format(score))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI related articles and clean"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# functions to clean text\n",
    "def is_empty(texts):\n",
    "    if (texts =='\\n') or (texts=='\\r'):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#clen wiki text\n",
    "def clean_wiki_text(texts):\n",
    "    if is_empty(texts):\n",
    "        return None\n",
    "    else:\n",
    "        texts = re.sub(r'\\[[0-9]*\\]', ' ', texts) #removes numbers\n",
    "        texts = re.sub(r'\\s+',' ',texts) #remove long blank space\n",
    "        return(texts)\n",
    "    \n",
    "articles = pd.read_csv(\"/home/zz3hs/git/dspg21RnD/data/dspg21RnD/wiki_ai_related_articles.csv\") #import csv\n",
    "\n",
    "texts = articles[\"article\"] #get the text\n",
    "\n",
    "text_clean_ls = []\n",
    "for text in texts:\n",
    "    text_clean = clean_wiki_text(text)\n",
    "    text_clean_ls.append(text_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1. Abstract on \"FROM ALPHAGO TO POWER SYSTEM ARTIFICIAL INTELLIGENCE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-655aa138c84e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mabstracts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/zz3hs/git/dspg21RnD/data/dspg21RnD/smaller-final-dataset.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/crystal_bert/lib/python3.8/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0;31m# We want to silence any warnings about, e.g. moved modules.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mexcs_to_catch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;31m# e.g.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/crystal_bert/lib/python3.8/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36m_frombuffer\u001b[0;34m(buf, dtype, shape, order)\u001b[0m\n\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_frombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1862\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "abstracts = pd.read_pickle(\"/home/zz3hs/git/dspg21RnD/data/dspg21RnD/smaller-final-dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original index</th>\n",
       "      <th>PROJECT_ID</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>FY</th>\n",
       "      <th>ORG_COUNT</th>\n",
       "      <th>PI_COUNT</th>\n",
       "      <th>nchar</th>\n",
       "      <th>final_frqwds_removed</th>\n",
       "      <th>PROJECT_TERMS</th>\n",
       "      <th>PROJECT_TITLE</th>\n",
       "      <th>...</th>\n",
       "      <th>ORGANIZATION_CITY</th>\n",
       "      <th>ORGANIZATION_STATE</th>\n",
       "      <th>ORGANIZATION_ZIP</th>\n",
       "      <th>ORGANIZATION_COUNTRY</th>\n",
       "      <th>BUDGET_START_DATE</th>\n",
       "      <th>BUDGET_END_DATE</th>\n",
       "      <th>CFDA_CODE</th>\n",
       "      <th>FY.y</th>\n",
       "      <th>FY_TOTAL_COST</th>\n",
       "      <th>FY_TOTAL_COST_SUB_PROJECTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>531810</th>\n",
       "      <td>1062091</td>\n",
       "      <td>1088974</td>\n",
       "      <td>The game of Go is an ancient board game which ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2379</td>\n",
       "      <td>[game, ancient, board, game, consider, far, bo...</td>\n",
       "      <td>Address; Algorithms; Area; Artificial Intelli...</td>\n",
       "      <td>FROM ALPHAGO TO POWER SYSTEM ARTIFICIAL INTELL...</td>\n",
       "      <td>...</td>\n",
       "      <td>KNOXVILLE</td>\n",
       "      <td>TN</td>\n",
       "      <td>37996-0003</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.041</td>\n",
       "      <td>2018</td>\n",
       "      <td>330000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        original index PROJECT_ID  \\\n",
       "531810         1062091    1088974   \n",
       "\n",
       "                                                 ABSTRACT    FY  ORG_COUNT  \\\n",
       "531810  The game of Go is an ancient board game which ...  2018          1   \n",
       "\n",
       "        PI_COUNT  nchar                               final_frqwds_removed  \\\n",
       "531810         1   2379  [game, ancient, board, game, consider, far, bo...   \n",
       "\n",
       "                                            PROJECT_TERMS  \\\n",
       "531810   Address; Algorithms; Area; Artificial Intelli...   \n",
       "\n",
       "                                            PROJECT_TITLE  ...  \\\n",
       "531810  FROM ALPHAGO TO POWER SYSTEM ARTIFICIAL INTELL...  ...   \n",
       "\n",
       "       ORGANIZATION_CITY ORGANIZATION_STATE ORGANIZATION_ZIP  \\\n",
       "531810         KNOXVILLE                 TN       37996-0003   \n",
       "\n",
       "       ORGANIZATION_COUNTRY BUDGET_START_DATE BUDGET_END_DATE CFDA_CODE  FY.y  \\\n",
       "531810        UNITED STATES               NaN             NaN    47.041  2018   \n",
       "\n",
       "       FY_TOTAL_COST FY_TOTAL_COST_SUB_PROJECTS  \n",
       "531810      330000.0                        NaN  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts[abstracts[\"PROJECT_TITLE\"] ==\"FROM ALPHAGO TO POWER SYSTEM ARTIFICIAL INTELLIGENCE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We feed in ML Wiki article as a query.\n",
    "For each sentence in the ML Wiki article, we identify the top 5 most similar/closest sentences from AI Wiki article based on cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Project SummaryGeneration of the eye, more so than many organs, requires precise control of its shape for optimal function.Obtaining knowledge of how the eye and lens is constructed during embryonic development is thereforeimportant to help describe the nature of ocular abnormalities that lead to major structural defects or moresubtle changes that alter vision. An example of a morphogenetic event required for the generation of organs isepithelial invagination. This process drives the inward bending of epithelia of several early organ systemsincluding that of the lens placode during early ocular development. Although several mechanisms have beenproposed to drive this process, such as apical constriction or local placodal growth, none have been foundsufficient to account for epithelial bending. We have recently observed that placodal cells change shape,move, and generate cytoskeletal structures in a planar polarized manner that produces a net flow of cellstoward the central placode. One of the hallmarks of planar-polarized cell movements such as these is theformation and resolution of cellular rosettes, an organized process of cell rearrangement that requires spatialrestriction of junctional proteins that contract and shorten junctions and proteins that lengthen and stabilizecellular junctions. We have identified planar-polarized localization of proteins responsible for junctionalcontraction (Shroom3 and p120-catenin) and stabilization (Par3 and cdc42). These results led us to ourcentral hypothesis that invagination is driven by a combination of epithelial cell movements and anisotropic cellshape changes organized by radial planar polarized protein localization, junction contraction, and junctionelongation. We will test this central hypothesis with three aims utilizing live-fluorescent microscopy ofgenetically altered mouse embryos. In aim 1 we will characterize the role of anisotropic junctional contractionand analyze the consequences of combined deficiency of Shroom3 and p120 catenin. The goal of aim 2 is tocharacterize the role of Par3 in junction elongation during rosette resolution and invagination. Aim 3 willinvestigate whether anisotropic cell geometry and movement results from the mutual antagonism betweenproteins that induce junctional contraction and junctional elongation. Once completed, the experiments in thisproposal will define the cell behaviors that drive the mechanisms of lens placode invagination.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_related_p = abstracts[\"ABSTRACT\"][531850]\n",
    "ai_related_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Project SummaryGeneration of the eye, more so than many organs, requires precise control of its shape for optimal function.Obtaining knowledge of how the eye and lens is constructed during embryonic development is thereforeimportant to help describe the nature of ocular abnormalities that lead to major structural defects or moresubtle changes that alter vision.', 'An example of a morphogenetic event required for the generation of organs isepithelial invagination.', 'This process drives the inward bending of epithelia of several early organ systemsincluding that of the lens placode during early ocular development.', 'Although several mechanisms have beenproposed to drive this process, such as apical constriction or local placodal growth, none have been foundsufficient to account for epithelial bending.', 'We have recently observed that placodal cells change shape,move, and generate cytoskeletal structures in a planar polarized manner that produces a net flow of cellstoward the central placode.', 'One of the hallmarks of planar-polarized cell movements such as these is theformation and resolution of cellular rosettes, an organized process of cell rearrangement that requires spatialrestriction of junctional proteins that contract and shorten junctions and proteins that lengthen and stabilizecellular junctions.', 'We have identified planar-polarized localization of proteins responsible for junctionalcontraction (Shroom3 and p120-catenin) and stabilization (Par3 and cdc42).', 'These results led us to ourcentral hypothesis that invagination is driven by a combination of epithelial cell movements and anisotropic cellshape changes organized by radial planar polarized protein localization, junction contraction, and junctionelongation.', 'We will test this central hypothesis with three aims utilizing live-fluorescent microscopy ofgenetically altered mouse embryos.', 'In aim 1 we will characterize the role of anisotropic junctional contractionand analyze the consequences of combined deficiency of Shroom3 and p120 catenin.', 'The goal of aim 2 is tocharacterize the role of Par3 in junction elongation during rosette resolution and invagination.', 'Aim 3 willinvestigate whether anisotropic cell geometry and movement results from the mutual antagonism betweenproteins that induce junctional contraction and junctional elongation.', 'Once completed, the experiments in thisproposal will define the cell behaviors that drive the mechanisms of lens placode invagination.']\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "get_score(5, ai_related_p, print_result = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2. Abstract on \"STRUCTURE OF SIGNAL PEPTIDE PEPTIDASE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The multiprotein complex y-secretase proteolytically cleaves the intramembrane region of amyloid precursorprotein (APP), which in turn forms the plaques found in Alzheimer's disease (AD) patients. The catalyticcomponent of Y-secretase is the intramembrane aspartyl protease (IAP) called presenilin. Mutations inpresenilin are directly linked to familial early-onset AD. Another known member of the IAP family is signalpeptide peptidase (SPP), which functions to further proteolyze remnant signal peptides after they have beencleaved by signal peptidase. Knowledge of the biochemistry and function of individual SPPs are onlybeginning to be elucidated, and homologues are found in all kingdoms of life. Presenilin and SPP exhibitsignificant sequence similarity, strongly suggesting they share structural and catalytic features. Thus, amolecular understanding of the more tractable SPP will likely impact drug design for presenilin and y-secretase. The goal of this proposal is to express, characterize, and solve the crystal structure of anextremophilic bacterial SPP ortholog by itself, with a transition-state analog inhibitor and with a substratemimic. In addition, drug candidates will be screened in silico. This first structure of an intramembraneprotease will provide critical insight into the biochemistry of intramembrane proteolysis and enable structure-based AD drug development and screening.\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_text = abstracts[\"ABSTRACT\"][0]#get the text\n",
    "abstract_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The multiprotein complex y-secretase proteolytically cleaves the intramembrane region of amyloid precursorprotein (APP), which in turn forms the plaques found in Alzheimer's disease (AD) patients.\", 'The catalyticcomponent of Y-secretase is the intramembrane aspartyl protease (IAP) called presenilin.', 'Mutations inpresenilin are directly linked to familial early-onset AD.', 'Another known member of the IAP family is signalpeptide peptidase (SPP), which functions to further proteolyze remnant signal peptides after they have beencleaved by signal peptidase.', 'Knowledge of the biochemistry and function of individual SPPs are onlybeginning to be elucidated, and homologues are found in all kingdoms of life.', 'Presenilin and SPP exhibitsignificant sequence similarity, strongly suggesting they share structural and catalytic features.', 'Thus, amolecular understanding of the more tractable SPP will likely impact drug design for presenilin and y-secretase.', 'The goal of this proposal is to express, characterize, and solve the crystal structure of anextremophilic bacterial SPP ortholog by itself, with a transition-state analog inhibitor and with a substratemimic.', 'In addition, drug candidates will be screened in silico.', 'This first structure of an intramembraneprotease will provide critical insight into the biochemistry of intramembrane proteolysis and enable structure-based AD drug development and screening.']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "get_score(5, abstract_text, print_result = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-4b74e7445b02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-8db3f58d9034>\u001b[0m in \u001b[0;36mget_score\u001b[0;34m(queries, print_result)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#compare each sentence in the abstract to the ai corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mquery_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# We use cosine-similarity and torch.topk to find the highest k scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/crystal_bert/lib/python3.8/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0moutput_value\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'token_embeddings'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/crystal_bert/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/crystal_bert/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/crystal_bert/lib/python3.8/site-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mtrans_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0moutput_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrans_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0moutput_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/crystal_bert/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/crystal_bert/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         )\n\u001b[0;32m--> 971\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    972\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/crystal_bert/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/crystal_bert/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    566\u001b[0m                 )\n\u001b[1;32m    567\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    569\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/crystal_bert/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/crystal_bert/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    457\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/crystal_bert/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/crystal_bert/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         )\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/crystal_bert/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/crystal_bert/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/crystal_bert/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/crystal_bert/lib/python3.8/site-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         return F.layer_norm(\n\u001b[0m\u001b[1;32m    174\u001b[0m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/crystal_bert/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2344\u001b[0m             \u001b[0mlayer_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2345\u001b[0m         )\n\u001b[0;32m-> 2346\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "get_score(queries, print_result=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_Basilica = \"Pope Julius' scheme for the grandest building in Christendom was the subject of a competition for which a number of entries remain intact in the Uffizi Gallery, Florence. It was the design of Donato Bramante that was selected, and for which the foundation stone was laid in 1506. This plan was in the form of an enormous Greek Cross with a dome inspired by that of the huge circular Roman temple, the Pantheon.[7] The main difference between Bramante's design and that of the Pantheon is that where the dome of the Pantheon is supported by a continuous wall, that of the new basilica was to be supported only on four large piers. This feature was maintained in the ultimate design. Bramante's dome was to be surmounted by a lantern with its own small dome but otherwise very similar in form to the Early Renaissance lantern of Florence Cathedral designed for Brunelleschi's dome by Michelozzo. Bramante had envisioned that the central dome would be surrounded by four lower domes at the diagonal axes. The equal chancel, nave and transept arms were each to be of two bays ending in an apse. At each corner of the building was to stand a tower, so that the overall plan was square, with the apses projecting at the cardinal points. Each apse had two large radial buttresses, which squared off its semi-circular shape.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Pope Julius' scheme for the grandest building in Christendom was the subject of a competition for which a number of entries remain intact in the Uffizi Gallery, Florence.\", 'It was the design of Donato Bramante that was selected, and for which the foundation stone was laid in 1506.', 'This plan was in the form of an enormous Greek Cross with a dome inspired by that of the huge circular Roman temple, the Pantheon.', \"[7] The main difference between Bramante's design and that of the Pantheon is that where the dome of the Pantheon is supported by a continuous wall, that of the new basilica was to be supported only on four large piers.\", 'This feature was maintained in the ultimate design.', \"Bramante's dome was to be surmounted by a lantern with its own small dome but otherwise very similar in form to the Early Renaissance lantern of Florence Cathedral designed for Brunelleschi's dome by Michelozzo.\", 'Bramante had envisioned that the central dome would be surrounded by four lower domes at the diagonal axes.', 'The equal chancel, nave and transept arms were each to be of two bays ending in an apse.', 'At each corner of the building was to stand a tower, so that the overall plan was square, with the apses projecting at the cardinal points.', 'Each apse had two large radial buttresses, which squared off its semi-circular shape.']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "queries = tokenize.sent_tokenize(text_Basilica)\n",
    "print(queries[0:10])\n",
    "print(len(queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Pope Julius' scheme for the grandest building in Christendom was the subject of a competition for which a number of entries remain intact in the Uffizi Gallery, Florence.\n",
      "Results: torch.return_types.topk(\n",
      "values=tensor([0.2273, 0.2086, 0.2030, 0.2018]),\n",
      "indices=tensor([ 53, 369,  22, 211]))\n",
      "\n",
      "Top k=5 most similar sentences in corpus:\n",
      "quiz show exhibition match, IBM's question answering system, Watson, defeated the two greatest Jeopardy! (Score: 0.2273)\n",
      "Thought-capable artificial beings appeared as storytelling devices since antiquity, \n",
      "and have been a persistent theme in science fiction. (Score: 0.2086)\n",
      "These issues have been explored by myth, fiction and philosophy since antiquity. (Score: 0.2030)\n",
      "This tradition, centered at Carnegie Mellon University would eventually culminate in the development of the Soar architecture in the middle 1980s. (Score: 0.2018)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: It was the design of Donato Bramante that was selected, and for which the foundation stone was laid in 1506.\n",
      "Results: torch.return_types.topk(\n",
      "values=tensor([0.1747, 0.1650, 0.1568, 0.1529]),\n",
      "indices=tensor([370, 206,  28, 356]))\n",
      "\n",
      "Top k=5 most similar sentences in corpus:\n",
      "A common trope in these works began with Mary Shelley's Frankenstein, where a human creation becomes a threat to its masters. (Score: 0.1747)\n",
      "During the 1960s, symbolic approaches had achieved great success at simulating high-level \"thinking\" in small demonstration programs. (Score: 0.1650)\n",
      "The study of mechanical or \"formal\" reasoning began with philosophers and mathematicians in antiquity. (Score: 0.1568)\n",
      "In January 2015, Musk donated $10 million to the Future of Life Institute to fund research on understanding AI decision making. (Score: 0.1529)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: This plan was in the form of an enormous Greek Cross with a dome inspired by that of the huge circular Roman temple, the Pantheon.\n",
      "Results: torch.return_types.topk(\n",
      "values=tensor([0.2661, 0.2561, 0.2545, 0.2447]),\n",
      "indices=tensor([211, 371,  22,  26]))\n",
      "\n",
      "Top k=5 most similar sentences in corpus:\n",
      "This tradition, centered at Carnegie Mellon University would eventually culminate in the development of the Soar architecture in the middle 1980s. (Score: 0.2661)\n",
      "This includes such works as Arthur C. Clarke's and Stanley Kubrick's 2001: A Space Odyssey (both 1968), with HAL 9000, the murderous computer in charge of the Discovery One spaceship, as well as The Terminator (1984) and The Matrix (1999). (Score: 0.2561)\n",
      "These issues have been explored by myth, fiction and philosophy since antiquity. (Score: 0.2545)\n",
      "Thought-capable artificial beings appeared as storytelling devices in antiquity,  and have been common in fiction, as in Mary Shelley's Frankenstein or Karel Čapek's R.U.R. (Score: 0.2447)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: [7] The main difference between Bramante's design and that of the Pantheon is that where the dome of the Pantheon is supported by a continuous wall, that of the new basilica was to be supported only on four large piers.\n",
      "Results: torch.return_types.topk(\n",
      "values=tensor([0.2857, 0.2283, 0.1860, 0.1650]),\n",
      "indices=tensor([211, 357,  22, 114]))\n",
      "\n",
      "Top k=5 most similar sentences in corpus:\n",
      "This tradition, centered at Carnegie Mellon University would eventually culminate in the development of the Soar architecture in the middle 1980s. (Score: 0.2857)\n",
      "The goal of the institute is to \"grow wisdom with which we manage\" the growing power of technology. (Score: 0.2283)\n",
      "These issues have been explored by myth, fiction and philosophy since antiquity. (Score: 0.1860)\n",
      "The cognitive capabilities of current architectures are very limited, using only a simplified version of what intelligence is really capable of. (Score: 0.1650)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: This feature was maintained in the ultimate design.\n",
      "Results: torch.return_types.topk(\n",
      "values=tensor([0.3845, 0.3560, 0.3249, 0.3157]),\n",
      "indices=tensor([225, 122, 228, 369]))\n",
      "\n",
      "Top k=5 most similar sentences in corpus:\n",
      "This includes embodied, situated, behavior-based, and nouvelle AI. (Score: 0.3845)\n",
      "These consist of particular traits or capabilities that researchers expect an intelligent system to display. (Score: 0.3560)\n",
      "This coincided with the development of the embodied mind thesis in the related field of cognitive science: the idea that aspects of the body (such as movement, perception and visualization) are required for higher intelligence. (Score: 0.3249)\n",
      "Thought-capable artificial beings appeared as storytelling devices since antiquity, \n",
      "and have been a persistent theme in science fiction. (Score: 0.3157)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Bramante's dome was to be surmounted by a lantern with its own small dome but otherwise very similar in form to the Early Renaissance lantern of Florence Cathedral designed for Brunelleschi's dome by Michelozzo.\n",
      "Results: torch.return_types.topk(\n",
      "values=tensor([0.3039, 0.1499, 0.1390, 0.1377]),\n",
      "indices=tensor([211,  26, 369, 357]))\n",
      "\n",
      "Top k=5 most similar sentences in corpus:\n",
      "This tradition, centered at Carnegie Mellon University would eventually culminate in the development of the Soar architecture in the middle 1980s. (Score: 0.3039)\n",
      "Thought-capable artificial beings appeared as storytelling devices in antiquity,  and have been common in fiction, as in Mary Shelley's Frankenstein or Karel Čapek's R.U.R. (Score: 0.1499)\n",
      "Thought-capable artificial beings appeared as storytelling devices since antiquity, \n",
      "and have been a persistent theme in science fiction. (Score: 0.1390)\n",
      "The goal of the institute is to \"grow wisdom with which we manage\" the growing power of technology. (Score: 0.1377)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Bramante had envisioned that the central dome would be surrounded by four lower domes at the diagonal axes.\n",
      "Results: torch.return_types.topk(\n",
      "values=tensor([0.3363, 0.1833, 0.1792, 0.1731]),\n",
      "indices=tensor([211,  95,  96,  12]))\n",
      "\n",
      "Top k=5 most similar sentences in corpus:\n",
      "This tradition, centered at Carnegie Mellon University would eventually culminate in the development of the Soar architecture in the middle 1980s. (Score: 0.3363)\n",
      "A fourth approach is harder to intuitively understand, but is inspired by how the brain's machinery works: the artificial neural network approach uses artificial \"neurons\" that can learn by comparing itself to the desired output and altering the strengths of the connections between its internal neurons to \"reinforce\" connections that seemed to be useful. (Score: 0.1833)\n",
      "These four main approaches can overlap with each other and with evolutionary systems; for example, neural nets can learn to make inferences, to generalize, and to make analogies. (Score: 0.1792)\n",
      "These sub-fields are based on technical considerations, such as particular goals (e.g. (Score: 0.1731)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: The equal chancel, nave and transept arms were each to be of two bays ending in an apse.\n",
      "Results: torch.return_types.topk(\n",
      "values=tensor([0.1978, 0.1703, 0.1625, 0.1611]),\n",
      "indices=tensor([  1, 135, 211, 296]))\n",
      "\n",
      "Top k=5 most similar sentences in corpus:\n",
      "The distinction between the former and the latter categories is often revealed by the acronym chosen. (Score: 0.1978)\n",
      "The most general ontologies are called upper ontologies, which attempt to provide a foundation for all other knowledge  by acting as mediators between domain ontologies that cover specific knowledge about a particular knowledge domain (field of interest or area of concern). (Score: 0.1703)\n",
      "This tradition, centered at Carnegie Mellon University would eventually culminate in the development of the Soar architecture in the middle 1980s. (Score: 0.1625)\n",
      "\"[l] Searle counters this assertion with his Chinese room argument, which asks us to look inside the computer and try to find where the \"mind\" might be. (Score: 0.1611)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: At each corner of the building was to stand a tower, so that the overall plan was square, with the apses projecting at the cardinal points.\n",
      "Results: torch.return_types.topk(\n",
      "values=tensor([0.3349, 0.2684, 0.2607, 0.2133]),\n",
      "indices=tensor([211,  91, 165, 138]))\n",
      "\n",
      "Top k=5 most similar sentences in corpus:\n",
      "This tradition, centered at Carnegie Mellon University would eventually culminate in the development of the Soar architecture in the middle 1980s. (Score: 0.3349)\n",
      "For example, when viewing a map and looking for the shortest driving route from Denver to New York in the East, one can in most cases skip looking at any path through San Francisco or other areas far to the West; thus, an AI wielding a pathfinding algorithm like A* can avoid the combinatorial explosion that would ensue if every possible route had to be ponderously considered. (Score: 0.2684)\n",
      "Such input is usually ambiguous; a giant, fifty-meter-tall pedestrian far away may produce the same pixels as a nearby normal-sized pedestrian, requiring the AI to judge the relative likelihood and reasonableness of different interpretations, for example by using its \"object model\" to assess that fifty-meter pedestrians do not exist. (Score: 0.2607)\n",
      "They need a way to visualize the future—a representation of the state of the world and be able to make predictions about how their actions will change it—and be able to make choices that maximize the utility (or \"value\") of available choices. (Score: 0.2133)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Each apse had two large radial buttresses, which squared off its semi-circular shape.\n",
      "Results: torch.return_types.topk(\n",
      "values=tensor([0.2252, 0.1974, 0.1924, 0.1786]),\n",
      "indices=tensor([211, 165, 117, 167]))\n",
      "\n",
      "Top k=5 most similar sentences in corpus:\n",
      "This tradition, centered at Carnegie Mellon University would eventually culminate in the development of the Soar architecture in the middle 1980s. (Score: 0.2252)\n",
      "Such input is usually ambiguous; a giant, fifty-meter-tall pedestrian far away may produce the same pixels as a nearby normal-sized pedestrian, requiring the AI to judge the relative likelihood and reasonableness of different interpretations, for example by using its \"object model\" to assess that fifty-meter pedestrians do not exist. (Score: 0.1974)\n",
      "This gives rise to two classes of models: structuralist and functionalist. (Score: 0.1924)\n",
      "Advanced robotic arms and other industrial robots, widely used in modern factories, can learn from experience how to move efficiently despite the presence of friction and gear slippage. (Score: 0.1786)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.22725766897201538,\n",
       "  0.2086402177810669,\n",
       "  0.20304988324642181,\n",
       "  0.20184537768363953],\n",
       " [0.17468996345996857,\n",
       "  0.16498778760433197,\n",
       "  0.15678071975708008,\n",
       "  0.15291136503219604],\n",
       " [0.2660845220088959,\n",
       "  0.25608712434768677,\n",
       "  0.2545034885406494,\n",
       "  0.24469813704490662],\n",
       " [0.2857217490673065,\n",
       "  0.22828024625778198,\n",
       "  0.18599683046340942,\n",
       "  0.1650390774011612],\n",
       " [0.38453492522239685,\n",
       "  0.35602161288261414,\n",
       "  0.3248547911643982,\n",
       "  0.31567105650901794],\n",
       " [0.30394724011421204,\n",
       "  0.14987064898014069,\n",
       "  0.1389949917793274,\n",
       "  0.13767722249031067],\n",
       " [0.33625566959381104,\n",
       "  0.18328112363815308,\n",
       "  0.17916186153888702,\n",
       "  0.1731284260749817],\n",
       " [0.19776922464370728,\n",
       "  0.17027877271175385,\n",
       "  0.1624986231327057,\n",
       "  0.16105715930461884],\n",
       " [0.3348667323589325,\n",
       "  0.26839780807495117,\n",
       "  0.2606987953186035,\n",
       "  0.21333608031272888],\n",
       " [0.2252057045698166,\n",
       "  0.19740983843803406,\n",
       "  0.19238469004631042,\n",
       "  0.17855817079544067]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(4, queries, print_result = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "# Find the closest k sentences of the AI corpus for each query sentence (ML) based on cosine similarity\n",
    "top_k = min(k, len(ai_corpus))\n",
    "\n",
    "query = queries[0]\n",
    "\n",
    "query_embedding = embedder.encode(query, show_progress_bar=False) \n",
    "\n",
    "# We use cosine-similarity and torch.topk to find the highest k scores\n",
    "cos_scores = util.pytorch_cos_sim(query_embedding, ai_embeddings)[0]\n",
    "\n",
    "top_results = torch.topk(cos_scores, k=top_k)   #get the top k scores\n",
    "result.append(top_results.values.tolist()) #unlist the top result list\n",
    "\n",
    "print(\"\\n\\n======================\\n\\n\")\n",
    "print(\"Query:\", query)\n",
    "print(\"Results:\", top_results)\n",
    "print(\"\\nTop k=5 most similar sentences in corpus:\")\n",
    "for score, idx in zip(top_results[0], top_results[1]):\n",
    "    print(ai_corpus[idx], \"(Score: {:.4f})\".format(score))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-crystal_bert]",
   "language": "python",
   "name": "conda-env-.conda-crystal_bert-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
